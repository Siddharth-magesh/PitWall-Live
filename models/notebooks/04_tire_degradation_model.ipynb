{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tire Degradation Prediction Model\n",
    "\n",
    "This notebook builds a time-series model to predict tire degradation curves.\n",
    "\n",
    "## Model Overview\n",
    "- **Task**: Time-series regression (predict degradation rate)\n",
    "- **Features**: Tire compound, age, driver style, track characteristics\n",
    "- **Algorithms**: LSTM, LightGBM, Linear Regression\n",
    "- **Target**: Seconds lost per lap due to tire wear\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "import joblib\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "# PyTorch for LSTM\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    from torch.utils.data import DataLoader, TensorDataset\n",
    "    TORCH_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TORCH_AVAILABLE = False\n",
    "    print(\"PyTorch not available. LSTM model will be skipped.\")\n",
    "\n",
    "import fastf1\n",
    "from fastf1 import get_session, get_event_schedule\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "CACHE_DIR = Path('../data/cache')\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "fastf1.Cache.enable_cache(str(CACHE_DIR))\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data and Extract Stints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_race_stints(year: int, grand_prix: str) -> pd.DataFrame:\n",
    "    \"\"\"Load lap data and identify tire stints.\"\"\"\n",
    "    try:\n",
    "        session = get_session(year, grand_prix, 'R')\n",
    "        session.load()\n",
    "        \n",
    "        laps = session.laps.copy()\n",
    "        laps['Season'] = year\n",
    "        laps['GrandPrix'] = grand_prix\n",
    "        \n",
    "        # Convert lap time\n",
    "        laps['LapTimeSeconds'] = laps['LapTime'].dt.total_seconds()\n",
    "        \n",
    "        # Filter valid laps\n",
    "        valid_laps = laps[\n",
    "            (laps['LapTimeSeconds'] > 60) &\n",
    "            (laps['LapTimeSeconds'] < 200) &\n",
    "            (laps['PitInTime'].isna()) &\n",
    "            (laps['PitOutTime'].isna()) &\n",
    "            (laps['LapNumber'] > 1)\n",
    "        ].copy()\n",
    "        \n",
    "        # Identify stints by compound changes\n",
    "        if 'Compound' in valid_laps.columns:\n",
    "            valid_laps = valid_laps.sort_values(['Driver', 'LapNumber'])\n",
    "            valid_laps['StintChange'] = (\n",
    "                (valid_laps['Compound'] != valid_laps['Compound'].shift()) | \n",
    "                (valid_laps['Driver'] != valid_laps['Driver'].shift())\n",
    "            )\n",
    "            valid_laps['StintNumber'] = valid_laps.groupby('Driver')['StintChange'].cumsum()\n",
    "            valid_laps['TireAge'] = valid_laps.groupby(['Driver', 'StintNumber']).cumcount() + 1\n",
    "        \n",
    "        return valid_laps\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {year} {grand_prix}: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from multiple races\n",
    "YEAR = 2023\n",
    "\n",
    "schedule = get_event_schedule(YEAR)\n",
    "race_events = schedule[schedule['EventFormat'] != 'testing']\n",
    "\n",
    "all_stints = []\n",
    "for _, event in tqdm(race_events.iterrows(), total=len(race_events)):\n",
    "    stint_data = load_race_stints(YEAR, event['EventName'])\n",
    "    if len(stint_data) > 0:\n",
    "        stint_data['Round'] = event['RoundNumber']\n",
    "        all_stints.append(stint_data)\n",
    "\n",
    "df = pd.concat(all_stints, ignore_index=True)\n",
    "print(f\"Loaded {len(df)} laps from {df['GrandPrix'].nunique()} races\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculate Degradation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_degradation_rate(stint_df: pd.DataFrame) -> dict:\n",
    "    \"\"\"Calculate degradation rate for a single stint using linear regression.\"\"\"\n",
    "    if len(stint_df) < 5:\n",
    "        return None\n",
    "    \n",
    "    x = stint_df['TireAge'].values.reshape(-1, 1)\n",
    "    y = stint_df['LapTimeSeconds'].values\n",
    "    \n",
    "    # Fit linear regression\n",
    "    model = LinearRegression()\n",
    "    model.fit(x, y)\n",
    "    \n",
    "    # Degradation rate = slope (seconds per lap)\n",
    "    deg_rate = model.coef_[0]\n",
    "    \n",
    "    return {\n",
    "        'DegradationRate': deg_rate,\n",
    "        'BaselapTime': model.intercept_,\n",
    "        'R2Score': model.score(x, y),\n",
    "        'StintLength': len(stint_df),\n",
    "        'AvgLapTime': y.mean(),\n",
    "        'BestLapTime': y.min(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate degradation for each stint\n",
    "stint_stats = []\n",
    "\n",
    "for (driver, gp, stint), group in tqdm(\n",
    "    df.groupby(['Driver', 'GrandPrix', 'StintNumber']),\n",
    "    desc=\"Calculating degradation\"\n",
    "):\n",
    "    stats = calculate_degradation_rate(group)\n",
    "    if stats:\n",
    "        stats['Driver'] = driver\n",
    "        stats['GrandPrix'] = gp\n",
    "        stats['StintNumber'] = stint\n",
    "        stats['Compound'] = group['Compound'].iloc[0] if 'Compound' in group else 'Unknown'\n",
    "        stats['StartLap'] = group['LapNumber'].min()\n",
    "        stats['EndLap'] = group['LapNumber'].max()\n",
    "        stint_stats.append(stats)\n",
    "\n",
    "stint_df = pd.DataFrame(stint_stats)\n",
    "print(f\"Calculated stats for {len(stint_df)} stints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze degradation by compound\n",
    "print(\"\\nDegradation Rate by Compound (seconds per lap):\")\n",
    "compound_deg = stint_df.groupby('Compound').agg({\n",
    "    'DegradationRate': ['mean', 'std', 'count'],\n",
    "    'StintLength': 'mean'\n",
    "}).round(4)\n",
    "compound_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize degradation curves by compound\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD']\n",
    "colors = {'SOFT': 'red', 'MEDIUM': 'yellow', 'HARD': 'gray'}\n",
    "\n",
    "for ax, compound in zip(axes, compounds):\n",
    "    compound_data = df[df['Compound'] == compound]\n",
    "    \n",
    "    # Sample a few stints\n",
    "    sample_stints = compound_data.groupby(['Driver', 'GrandPrix', 'StintNumber']).ngroups\n",
    "    \n",
    "    for (driver, gp, stint), group in list(compound_data.groupby(['Driver', 'GrandPrix', 'StintNumber']))[:20]:\n",
    "        if len(group) >= 5:\n",
    "            ax.plot(group['TireAge'], group['LapTimeSeconds'], \n",
    "                    alpha=0.3, color=colors[compound])\n",
    "    \n",
    "    ax.set_xlabel('Tire Age (Laps)')\n",
    "    ax.set_ylabel('Lap Time (seconds)')\n",
    "    ax.set_title(f'{compound} Tire Degradation')\n",
    "    ax.set_xlim(0, 35)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build Degradation Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features for predicting degradation rate\n",
    "# Encode compounds\n",
    "compound_map = {'SOFT': 0, 'MEDIUM': 1, 'HARD': 2, 'INTERMEDIATE': 3, 'WET': 4}\n",
    "stint_df['CompoundEncoded'] = stint_df['Compound'].map(compound_map).fillna(1)\n",
    "\n",
    "# Add circuit encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "circuit_encoder = LabelEncoder()\n",
    "stint_df['CircuitEncoded'] = circuit_encoder.fit_transform(stint_df['GrandPrix'])\n",
    "\n",
    "# Driver encoding\n",
    "driver_encoder = LabelEncoder()\n",
    "stint_df['DriverEncoded'] = driver_encoder.fit_transform(stint_df['Driver'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features for stint-level degradation prediction\n",
    "FEATURE_COLS = [\n",
    "    'CompoundEncoded',\n",
    "    'CircuitEncoded',\n",
    "    'DriverEncoded',\n",
    "    'StintNumber',  # First stint vs later stints\n",
    "    'StartLap',     # When stint started (fuel load proxy)\n",
    "]\n",
    "\n",
    "TARGET_COL = 'DegradationRate'\n",
    "\n",
    "# Filter valid stints (positive degradation, reasonable R2)\n",
    "valid_stints = stint_df[\n",
    "    (stint_df['DegradationRate'] > 0) &\n",
    "    (stint_df['DegradationRate'] < 0.5) &\n",
    "    (stint_df['R2Score'] > 0.3) &\n",
    "    (stint_df['StintLength'] >= 8)\n",
    "]\n",
    "\n",
    "print(f\"Valid stints for modeling: {len(valid_stints)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = valid_stints[FEATURE_COLS]\n",
    "y = valid_stints[TARGET_COL]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: LightGBM\n",
    "print(\"Training LightGBM...\")\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    random_state=RANDOM_SEED,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "lgb_pred = lgb_model.predict(X_test)\n",
    "lgb_mae = mean_absolute_error(y_test, lgb_pred)\n",
    "lgb_r2 = r2_score(y_test, lgb_pred)\n",
    "\n",
    "print(f\"\\nLightGBM Results:\")\n",
    "print(f\"  MAE: {lgb_mae:.4f} s/lap\")\n",
    "print(f\"  R²: {lgb_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: Ridge Regression (simpler baseline)\n",
    "print(\"Training Ridge Regression...\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "ridge_pred = ridge_model.predict(X_test_scaled)\n",
    "ridge_mae = mean_absolute_error(y_test, ridge_pred)\n",
    "ridge_r2 = r2_score(y_test, ridge_pred)\n",
    "\n",
    "print(f\"\\nRidge Regression Results:\")\n",
    "print(f\"  MAE: {ridge_mae:.4f} s/lap\")\n",
    "print(f\"  R²: {ridge_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LSTM Model for Sequence Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TORCH_AVAILABLE:\n",
    "    class TireDegradationLSTM(nn.Module):\n",
    "        \"\"\"LSTM model for predicting lap-by-lap degradation.\"\"\"\n",
    "        \n",
    "        def __init__(self, input_size=5, hidden_size=32, num_layers=2, output_size=1):\n",
    "            super().__init__()\n",
    "            \n",
    "            self.lstm = nn.LSTM(\n",
    "                input_size=input_size,\n",
    "                hidden_size=hidden_size,\n",
    "                num_layers=num_layers,\n",
    "                batch_first=True,\n",
    "                dropout=0.2\n",
    "            )\n",
    "            \n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Linear(hidden_size, 16),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(16, output_size)\n",
    "            )\n",
    "        \n",
    "        def forward(self, x):\n",
    "            lstm_out, _ = self.lstm(x)\n",
    "            # Use last hidden state\n",
    "            last_hidden = lstm_out[:, -1, :]\n",
    "            out = self.fc(last_hidden)\n",
    "            return out\n",
    "    \n",
    "    print(\"LSTM model defined\")\n",
    "else:\n",
    "    print(\"Skipping LSTM (PyTorch not available)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TORCH_AVAILABLE:\n",
    "    def prepare_sequences(df, seq_length=10):\n",
    "        \"\"\"Prepare sequences for LSTM training.\"\"\"\n",
    "        sequences = []\n",
    "        targets = []\n",
    "        \n",
    "        for (driver, gp, stint), group in df.groupby(['Driver', 'GrandPrix', 'StintNumber']):\n",
    "            if len(group) < seq_length + 1:\n",
    "                continue\n",
    "            \n",
    "            group = group.sort_values('TireAge')\n",
    "            \n",
    "            # Features: TireAge, Compound, normalized lap time delta\n",
    "            compound_enc = {'SOFT': 0, 'MEDIUM': 0.5, 'HARD': 1}.get(group['Compound'].iloc[0], 0.5)\n",
    "            \n",
    "            lap_times = group['LapTimeSeconds'].values\n",
    "            base_time = lap_times[0]\n",
    "            normalized_times = (lap_times - base_time) / base_time  # Percentage change\n",
    "            \n",
    "            for i in range(len(group) - seq_length):\n",
    "                seq_features = []\n",
    "                for j in range(seq_length):\n",
    "                    idx = i + j\n",
    "                    features = [\n",
    "                        group['TireAge'].iloc[idx] / 50,  # Normalized tire age\n",
    "                        compound_enc,\n",
    "                        normalized_times[idx],\n",
    "                        (group['LapNumber'].iloc[idx] / 70),  # Normalized lap number\n",
    "                        0.5,  # Placeholder for additional features\n",
    "                    ]\n",
    "                    seq_features.append(features)\n",
    "                \n",
    "                sequences.append(seq_features)\n",
    "                # Target: next lap time delta\n",
    "                targets.append(normalized_times[i + seq_length])\n",
    "        \n",
    "        return np.array(sequences), np.array(targets)\n",
    "    \n",
    "    # Prepare data\n",
    "    print(\"Preparing sequences...\")\n",
    "    X_seq, y_seq = prepare_sequences(df, seq_length=8)\n",
    "    print(f\"Sequences shape: {X_seq.shape}\")\n",
    "    print(f\"Targets shape: {y_seq.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TORCH_AVAILABLE and len(X_seq) > 100:\n",
    "    # Convert to tensors\n",
    "    X_tensor = torch.FloatTensor(X_seq)\n",
    "    y_tensor = torch.FloatTensor(y_seq).unsqueeze(1)\n",
    "    \n",
    "    # Split\n",
    "    split_idx = int(len(X_tensor) * 0.8)\n",
    "    X_train_lstm = X_tensor[:split_idx]\n",
    "    y_train_lstm = y_tensor[:split_idx]\n",
    "    X_test_lstm = X_tensor[split_idx:]\n",
    "    y_test_lstm = y_tensor[split_idx:]\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = TensorDataset(X_train_lstm, y_train_lstm)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    # Initialize model\n",
    "    lstm_model = TireDegradationLSTM(input_size=5, hidden_size=32)\n",
    "    optimizer = torch.optim.Adam(lstm_model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Train\n",
    "    print(\"Training LSTM...\")\n",
    "    lstm_model.train()\n",
    "    \n",
    "    for epoch in range(50):\n",
    "        total_loss = 0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = lstm_model(batch_X)\n",
    "            loss = criterion(output, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.6f}\")\n",
    "    \n",
    "    # Evaluate\n",
    "    lstm_model.eval()\n",
    "    with torch.no_grad():\n",
    "        lstm_pred = lstm_model(X_test_lstm).numpy()\n",
    "    \n",
    "    lstm_mae = mean_absolute_error(y_test_lstm.numpy(), lstm_pred)\n",
    "    print(f\"\\nLSTM MAE: {lstm_mae:.6f}\")\n",
    "else:\n",
    "    print(\"Skipping LSTM training (insufficient data or PyTorch unavailable)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tire Cliff Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_tire_cliff(stint_laps: pd.DataFrame, threshold: float = 0.5) -> dict:\n",
    "    \"\"\"\n",
    "    Detect when tires \"fall off the cliff\" - sudden performance drop.\n",
    "    \n",
    "    Args:\n",
    "        stint_laps: Lap data for a single stint\n",
    "        threshold: Seconds jump to consider a cliff\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with cliff detection info\n",
    "    \"\"\"\n",
    "    if len(stint_laps) < 5:\n",
    "        return {'has_cliff': False}\n",
    "    \n",
    "    stint_laps = stint_laps.sort_values('TireAge')\n",
    "    lap_times = stint_laps['LapTimeSeconds'].values\n",
    "    tire_ages = stint_laps['TireAge'].values\n",
    "    \n",
    "    # Calculate lap-to-lap deltas\n",
    "    deltas = np.diff(lap_times)\n",
    "    \n",
    "    # Find sudden jumps\n",
    "    cliff_indices = np.where(deltas > threshold)[0]\n",
    "    \n",
    "    if len(cliff_indices) > 0:\n",
    "        cliff_lap = tire_ages[cliff_indices[0] + 1]\n",
    "        cliff_delta = deltas[cliff_indices[0]]\n",
    "        return {\n",
    "            'has_cliff': True,\n",
    "            'cliff_tire_age': cliff_lap,\n",
    "            'cliff_delta': cliff_delta\n",
    "        }\n",
    "    \n",
    "    return {'has_cliff': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze tire cliffs\n",
    "cliff_results = []\n",
    "\n",
    "for (driver, gp, stint), group in df.groupby(['Driver', 'GrandPrix', 'StintNumber']):\n",
    "    if len(group) >= 10:\n",
    "        result = detect_tire_cliff(group)\n",
    "        result['Driver'] = driver\n",
    "        result['GrandPrix'] = gp\n",
    "        result['Compound'] = group['Compound'].iloc[0] if 'Compound' in group else 'Unknown'\n",
    "        cliff_results.append(result)\n",
    "\n",
    "cliff_df = pd.DataFrame(cliff_results)\n",
    "\n",
    "# Summary by compound\n",
    "cliff_summary = cliff_df.groupby('Compound').agg({\n",
    "    'has_cliff': ['sum', 'count'],\n",
    "}).round(2)\n",
    "cliff_summary.columns = ['Cliffs_Detected', 'Total_Stints']\n",
    "cliff_summary['Cliff_Rate'] = (cliff_summary['Cliffs_Detected'] / cliff_summary['Total_Stints'] * 100).round(1)\n",
    "\n",
    "print(\"\\nTire Cliff Analysis by Compound:\")\n",
    "cliff_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cliff tire age distribution\n",
    "cliffs_with_age = cliff_df[cliff_df['has_cliff'] == True]\n",
    "\n",
    "if len(cliffs_with_age) > 0:\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    for compound in ['SOFT', 'MEDIUM', 'HARD']:\n",
    "        compound_cliffs = cliffs_with_age[cliffs_with_age['Compound'] == compound]\n",
    "        if len(compound_cliffs) > 0:\n",
    "            ax.hist(compound_cliffs['cliff_tire_age'], bins=15, alpha=0.5, \n",
    "                    label=compound, edgecolor='black')\n",
    "    \n",
    "    ax.set_xlabel('Tire Age at Cliff (Laps)')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title('When Do Tires Fall Off the Cliff?')\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save degradation prediction model\n",
    "models_dir = Path('../saved_models')\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "model_path = models_dir / 'tire_degradation_lgb_v1.joblib'\n",
    "joblib.dump({\n",
    "    'model': lgb_model,\n",
    "    'feature_cols': FEATURE_COLS,\n",
    "    'circuit_encoder': circuit_encoder,\n",
    "    'driver_encoder': driver_encoder,\n",
    "    'compound_map': compound_map,\n",
    "    'metrics': {'mae': lgb_mae, 'r2': lgb_r2},\n",
    "    'created_at': datetime.now().isoformat()\n",
    "}, model_path)\n",
    "\n",
    "print(f\"Model saved to: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prediction Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_degradation_curve(\n",
    "    model,\n",
    "    compound: str,\n",
    "    circuit: str,\n",
    "    driver: str,\n",
    "    base_lap_time: float,\n",
    "    max_laps: int = 40\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Predict tire degradation curve.\n",
    "    \n",
    "    Returns predicted lap times for each tire age.\n",
    "    \"\"\"\n",
    "    # Get encodings (use defaults if unknown)\n",
    "    compound_enc = compound_map.get(compound, 1)\n",
    "    \n",
    "    try:\n",
    "        circuit_enc = circuit_encoder.transform([circuit])[0]\n",
    "    except:\n",
    "        circuit_enc = 0\n",
    "    \n",
    "    try:\n",
    "        driver_enc = driver_encoder.transform([driver])[0]\n",
    "    except:\n",
    "        driver_enc = 0\n",
    "    \n",
    "    # Predict degradation rate\n",
    "    features = pd.DataFrame([{\n",
    "        'CompoundEncoded': compound_enc,\n",
    "        'CircuitEncoded': circuit_enc,\n",
    "        'DriverEncoded': driver_enc,\n",
    "        'StintNumber': 1,\n",
    "        'StartLap': 1,\n",
    "    }])\n",
    "    \n",
    "    deg_rate = model.predict(features[FEATURE_COLS])[0]\n",
    "    \n",
    "    # Generate curve\n",
    "    tire_ages = np.arange(1, max_laps + 1)\n",
    "    predicted_times = base_lap_time + (deg_rate * tire_ages)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'TireAge': tire_ages,\n",
    "        'PredictedLapTime': predicted_times,\n",
    "        'DegradationRate': deg_rate\n",
    "    })\n",
    "\n",
    "# Example prediction\n",
    "example = predict_degradation_curve(\n",
    "    lgb_model,\n",
    "    compound='MEDIUM',\n",
    "    circuit='Bahrain Grand Prix',\n",
    "    driver='VER',\n",
    "    base_lap_time=92.0,\n",
    "    max_laps=35\n",
    ")\n",
    "\n",
    "print(f\"\\nPredicted degradation rate: {example['DegradationRate'].iloc[0]:.4f} s/lap\")\n",
    "print(f\"\\nPredicted curve (sample):\")\n",
    "example.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize prediction\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "for compound in ['SOFT', 'MEDIUM', 'HARD']:\n",
    "    curve = predict_degradation_curve(\n",
    "        lgb_model,\n",
    "        compound=compound,\n",
    "        circuit='Bahrain Grand Prix',\n",
    "        driver='VER',\n",
    "        base_lap_time=92.0,\n",
    "        max_laps=40\n",
    "    )\n",
    "    \n",
    "    colors = {'SOFT': 'red', 'MEDIUM': 'gold', 'HARD': 'gray'}\n",
    "    ax.plot(curve['TireAge'], curve['PredictedLapTime'], \n",
    "            color=colors[compound], linewidth=2, label=compound)\n",
    "\n",
    "ax.set_xlabel('Tire Age (Laps)')\n",
    "ax.set_ylabel('Predicted Lap Time (seconds)')\n",
    "ax.set_title('Predicted Tire Degradation Curves')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Findings:\n",
    "1. **Soft tires** degrade fastest (~0.08-0.12 s/lap)\n",
    "2. **Hard tires** are most durable (~0.03-0.06 s/lap)\n",
    "3. **Tire cliff** is more common with soft tires\n",
    "\n",
    "### Applications:\n",
    "- Pit stop timing optimization\n",
    "- Strategy simulation\n",
    "- Undercut/overcut prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
